\section{Kompleksitet} \label{kap:kompleksitet}
%side 250 ish
%table 1 side 247 i pdf.

Der findes to former for kompleksitet, men vi vælger at fokusere på tidskompleksitet. Den anden form for kompleksitet er pladskompleksitet. 
Der er tre former for tilfælde: bedste, værste og det gennemsnitlige. 

\emph{Bedste tilfælde} beskriver algoritmen under optimale forhold, i en lineær søgealgoritme vil dette altså være, at elementet der søges efter, er det første element i listen. På samme måde er \emph{værste tilfælde} en situation, hvori elementet der søges efter ikke findes eller er på sidste plads i listen over elementer.
Oftere ser man på enten værste tilfælde eller \emph{gennemsnitlige tilfælde}. 
Det gennemsnitlige tilfælde vil give et rigtigt godt overblik over hvor god algoritmen er, dog er det meget svært at bestemme, hvad et gennemsnitligt input er, da det er svært at bestemme nogle parametre at vælge ud fra. 
Det værste tilfælde giver et godt overblik over, hvor lang tid det kan tage. Ved man, at algoritmen er lineær i værste tilfælde, vil man kunne løse den i rimelig tid for alle størrelser, $n$.
De forskellige resultater i vores analyse af algoritmerne kan deles op i kategorier, de mest gængse er: $\log n$, $\sqrt{n}$, $n$, $n^x$, $x^n$ og $n!$, men det kan også være en kombination af disse, som $n!n$, $n\log n$ eller lignende.
For at beskrive disse algoritmer i fx værste tilfælde, vil man bruge operatorerne \emph{store-O}, \emph{store-$\Omega$} og \emph{store-$\Theta$}. Man vil her fokusere på \emph{asymptotiske $n$-værdier}, altså gående mod $\infty$, da man i nogle tilfælde vil have en algoritme, der er langsommere end den \emph{øvre bindende funktion} ved små $n$, men ved større, som fx over 10.000, er hurtigere.

\subsection{Store-$O$}
\begin{defn}
$f(n)= O(g(n))$, hvis og kun hvis $\exists$ positive konstanter $C$ og $n_o$, så $|f(n)| \leq C |g(n)| \forall n \geq n_o$.
\end{defn}

Store-$O$ bliver brugt til at binde funktionen opadtil, begrænse den oppefra. Man kan med garanti sige, at algoritmen tager store-$O$ tid eller mindre. 
\begin{exmp}
\begin{align}
\begin{split}
f(n)=& 13n+3 \\
13n+3 \leq& 20n \forall \ n \geq 1 \\
f(n) =& O(n).
\end{split}
\end{align}
\end{exmp}
Man vil også kunne sige, at $f(n)$ er mindre end $n!$ eller en anden vilkårlig, højere funktion, $g(n)$, men da man altid vil vælge den mest begrænsende funktion, vil $n$ være det mest præcise. 

\subsection{Store-$\Omega$}
\begin{defn}
$f(n) = \Omega(g(n))$, hvis og kun hvis $\exists$ positive konstanter $C$ og $n_o$, så $|f(n)| \geq C |g(n)| \forall n \geq n_o$.
\end{defn}
Store-$\Omega$ bruges, modsat store-$O$, til at binde funktionen nedadtil, altså finde den nedre grænse for algoritmen. Den vil mindst tage store-$\Omega$ tid i det givne tilfælde.
\begin{exmp}
\begin{align}
\begin{split}
f(n)=& 13n+3 \\
13n+3 \geq& n \forall \ n \geq 1 \\
f(n) =& \Omega(n).
\end{split}
\end{align}
\end{exmp}

På samme måde som ved store-$O$-notationen vil man her kunne vælge en vilkårlig mindre funktion, $\log n$, $1$ med flere, men da man vil begrænse den så meget som muligt, vælger man den største funktion, $g(n)$, hvor uligheden stadig er sand.
\subsection{Store-$\Theta$}
\begin{defn}
$f(n) = \Theta(g(x))$, hvis og kun hvis $\exists$ positive konstanter $C_1, C_2$ og $n_o$, så $C_1|g(n)| \leq |f(n)| \leq C_2|g(n)| \forall n \geq n_o$.
\end{defn}
Når man har fundet den øvre og nedre grænse, store-O og store-$\Omega$, kan man finde den tætbundne funktion, store-$\Theta$.
\begin{exmp}
\begin{align}
\begin{split}
f(n)=& 13n+3 \\
\Omega(n) \leq& f(n) \leq O(n) \\
n \leq& 13n+3 \leq 10n \forall \ n \geq 1 \\
f(n) =& \Theta(n).
\end{split}
\end{align}
\end{exmp}

I følgende afsnit tager vi udgangspunkt i to sorteringer og ser, hvordan de sammenligner sig på store-$O$ i bedste og værste tilfælde.

\subsection{Kompleksitet af bubblesortering} \label{kap:kom_bubble}

For at finde kompleksiteten af bubblesortering bruger vi store-$O$-notationen fra tidligere. 
Bubblesortering, som nævnt i \autoref{kap:sortering}, sammenligner to elementer fra listen og flytter rundt på dem, hvis de står i forkert rækkefølge.
Vi starter med værste tilfælde. Her ser vi på en liste, $P$, der er sorteret i omvendt rækkefølge, $(5,4,3,2,1)$.
I første iteration sammenligner den 5 med 4 og bytter om, 5 med 3, bytter igen, 5 med 2, bytter, og til sidst 5 med 1. Nu står 5 korrekt, og $(4, 3, 2, 1, 5)$.
Efter næste iteration er $(3, 2, 1, 4, 5)$, og de sidste iteration medfører hhv. $(2, 1, 3, 4, 5)$ og $(1, 2, 3, 4, 5)$. Her ses altså, at der itereres 4 gange, eller $n-1$ gange. 
For hver iteration, $i$, sammenligner den $n-i$ gange. 
Som vi kender fra tidligere teori, tælles de mindre ordner ikke med, derved er kompleksiteten $O(n\times n)$ eller $O(n^2)$.

I bedste tilfælde er listen $(1, 2, 3, 4, 5)$.
I vores algoritme, stopper algoritmen først, når den har lavet $n-1$ iterationer, og stopper dermed ikke på trods af at listen kan være i korrekt rækkefølge tidligere. I bedste tilfælde, vil den derfor være lige så kompleks som vores værste tilfælde, altså $O(n^2)$. Det vil dog være relativt nemt at optimere algoritmen, så den stopper, hvis den ikke laver flere ombytninger i en given iteration. Denne optimering vil gøre algoritmen $O(n)$ i bedste fald, da den i dette tilfælde kun gennemfører én iteration, og der stadig udføres $n-1$ sammenligninger i denne iteration. 

\subsection{Kompleksitet af indskudssortering} \label{kap:kom_indskud}
En anden sorteringsalgoritme er indskudssorteringen fra \autoref{kap:sortering}. Denne tager udgangspunkt i et enkelt element ad gangen og sammenligner dette med resten af den korrekte liste.
Hvis vi igen benytter det værste tilfælde, når listen er $(1,2,3,4,5)$, ser vi, at den først tager $2$-tallet og sammenligner med $1$-tallet. Den ser først, at to er større end en, og siden der kun er et element i den korrekte liste, vil den placere to til højre for et. Det næste element, den så tjekker, er tre, som den først sammenligner med et og derefter to for så til sidst at placere det længst til højre. På denne måde indsættes de sidste to elementer i forhold til den korrekte liste.
Vi ser her, at der på samme måde som med bubblesortering køres fire iterationer. Der er i første iteration en sammenligning, derefter to sammenligninger i anden iteration og $n$ sammenligninger i $n$'te iteration. Hermed er denne sortering også $O(n^2)$ i værste fald.


I bedste fald, når listen er $(5,4,3,2,1)$, har den en lineær kompleksitet, da den i alle iterationer kun sammenligner med det element, der er længst til venstre, hvorefter det er indsat korrekt, dermed er kompleksiteten $O(n)$.



%P \\
%NP \\
%NP-Complete \\
%NP-Hard. 


